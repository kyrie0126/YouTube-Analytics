{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('YT_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find trending videos per query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_json = build('youtube', 'v3', developerKey=api_key).search().list(\n",
    "            part='snippet',\n",
    "            maxResults=50,\n",
    "            q='fishing',\n",
    "            order='viewCount',\n",
    "            type='video',\n",
    "            regionCode='US',\n",
    "            videoDuration='medium',\n",
    "            publishedAfter='2023-08-01T00:00:00Z'\n",
    "        ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user, user_id, vid_id, title, date = [], [], [], [], []\n",
    "\n",
    "for item in req_json['items']:\n",
    "    user.append(item['snippet']['channelTitle'])\n",
    "    user_id.append(item['snippet']['channelId'])\n",
    "    vid_id.append(item['id']['videoId'])\n",
    "    title.append(item['snippet']['title'])\n",
    "    date.append(item['snippet']['publishTime'])\n",
    "\n",
    "df_temp = pd.DataFrame({\n",
    "    'username': user,\n",
    "    'user_id':user_id,\n",
    "    'vid_id': vid_id,\n",
    "    'date': date,\n",
    "    'title': title\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find subscribers per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_out = \"\"\n",
    "for i in set(user_id):\n",
    "    user_id_out += i + ','\n",
    "user_id_out = user_id_out[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_json = build('youtube', 'v3', developerKey=api_key).channels().list(\n",
    "            part='statistics',\n",
    "            id=user_id_out\n",
    "        ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = {}\n",
    "for i in subs_json['items']:\n",
    "    channel_id = i['id']\n",
    "    subs[channel_id] = i['statistics']['subscriberCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subs = pd.DataFrame(subs.items(), columns=['user_id','subscribers'])\n",
    "df_subs['subscribers'] = df_subs['subscribers'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find views per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_id_out = \"\"\n",
    "for val in set(vid_id):\n",
    "    vid_id_out += val + ','\n",
    "vid_id_out = vid_id_out[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "views_json = build('youtube', 'v3', developerKey=api_key).videos().list(\n",
    "            part='statistics, contentDetails',\n",
    "            id=vid_id_out\n",
    "        ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "views = {}\n",
    "for i in views_json['items']:\n",
    "    vid_id = i['id']\n",
    "    views[vid_id] = i['statistics']['viewCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_views = pd.DataFrame(views.items(), columns=['vid_id','views'])\n",
    "df_views['views'] = df_views['views'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_temp.merge(df_subs, how='left', on='user_id')\n",
    "df = df.merge(df_views, how='left', on='vid_id')\n",
    "df['viewsToSubs'] = df['views']/df['subscribers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which videos received the most views per subscriber?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>user_id</th>\n",
       "      <th>vid_id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>views</th>\n",
       "      <th>viewsToSubs</th>\n",
       "      <th>audio_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Lawless Tide</td>\n",
       "      <td>UCqD-eS-qRKsGi9LfT-4jiJA</td>\n",
       "      <td>RpNfMFNz2VM</td>\n",
       "      <td>2023-10-18T20:55:00Z</td>\n",
       "      <td>Someone Called the GAME WARDEN Because I Was C...</td>\n",
       "      <td>32600</td>\n",
       "      <td>4437572</td>\n",
       "      <td>136.121840</td>\n",
       "      <td>oh God this is a beast definitely biggest I've...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Tom Epic</td>\n",
       "      <td>UC57qJQqeVCq2BUTqvpBsHXw</td>\n",
       "      <td>EGhvfudN390</td>\n",
       "      <td>2023-08-31T21:06:11Z</td>\n",
       "      <td>DIY Saltwater  Fish Pond  At The Beach  With A...</td>\n",
       "      <td>18500</td>\n",
       "      <td>851710</td>\n",
       "      <td>46.038378</td>\n",
       "      <td>thank you thank you foreign thank you foreign ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Whimsy World</td>\n",
       "      <td>UCn-yQfooWz39iQQpWYVOHdA</td>\n",
       "      <td>MlQlpU3uyss</td>\n",
       "      <td>2023-10-16T11:42:13Z</td>\n",
       "      <td>Amazing! Attractive Best Best Big Fish Market ...</td>\n",
       "      <td>28300</td>\n",
       "      <td>1185058</td>\n",
       "      <td>41.874841</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Sabang Angler</td>\n",
       "      <td>UCxBVjI9xUjgcsJ-_z2aHjgQ</td>\n",
       "      <td>8pXx4MUDXJM</td>\n",
       "      <td>2023-09-05T11:05:21Z</td>\n",
       "      <td>Galit na Galit mga isda sa Pain ko !</td>\n",
       "      <td>20100</td>\n",
       "      <td>647668</td>\n",
       "      <td>32.222289</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Adventure Fishing UK</td>\n",
       "      <td>UC7Da9nUj8TXcKwQlULbcpBQ</td>\n",
       "      <td>QQ7CU-CLkz0</td>\n",
       "      <td>2023-09-10T13:30:12Z</td>\n",
       "      <td>I Hiked HOURS to Fish this TINY Mountain Pond....</td>\n",
       "      <td>25700</td>\n",
       "      <td>573893</td>\n",
       "      <td>22.330467</td>\n",
       "      <td>fish on Fish on fish on yeah yes come on I thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Kapuso mo, Jessica Stories</td>\n",
       "      <td>UC_ktPLZUDrSXNOyFzhQbMpA</td>\n",
       "      <td>iXJqAxXqKS8</td>\n",
       "      <td>2023-10-15T11:00:29Z</td>\n",
       "      <td>Kapuso mo, Jessica soho: DAMBUHALANG COBRA, SI...</td>\n",
       "      <td>69300</td>\n",
       "      <td>684191</td>\n",
       "      <td>9.872886</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Final Affliction</td>\n",
       "      <td>UCcOCstS20fFk383lSHo7ifw</td>\n",
       "      <td>KvB73Ziaa70</td>\n",
       "      <td>2023-09-08T07:11:38Z</td>\n",
       "      <td>The HORRIFYING Last Minutes of Gloria Serge EA...</td>\n",
       "      <td>371000</td>\n",
       "      <td>3258808</td>\n",
       "      <td>8.783849</td>\n",
       "      <td>in today's episode an elderly woman's dog is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Dung Girl Fishing</td>\n",
       "      <td>UCytnlBRb1zB8QUAZDvJr6lw</td>\n",
       "      <td>Z8PaNFb8Is8</td>\n",
       "      <td>2023-08-27T12:44:44Z</td>\n",
       "      <td>Amazing Fishing | Beautiful Girl Fishing Big a...</td>\n",
       "      <td>88600</td>\n",
       "      <td>742422</td>\n",
       "      <td>8.379481</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>village food taste</td>\n",
       "      <td>UCaCUtSfruaAfE3gqeT5ZHVg</td>\n",
       "      <td>6_fesOKe7NY</td>\n",
       "      <td>2023-09-30T09:33:38Z</td>\n",
       "      <td>Pond Water Fish Catching and Cooking Fish Grav...</td>\n",
       "      <td>416000</td>\n",
       "      <td>3387712</td>\n",
       "      <td>8.143538</td>\n",
       "      <td>foreign all right thank you thank you thank yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wild Fighter</td>\n",
       "      <td>UCc_lepicYywQXEvyeJcz1TA</td>\n",
       "      <td>dMZTwIDN5Bk</td>\n",
       "      <td>2023-08-14T12:26:05Z</td>\n",
       "      <td>Shark Attack Man In Sea Fishing Boat | Fun Mad...</td>\n",
       "      <td>572000</td>\n",
       "      <td>4159510</td>\n",
       "      <td>7.271871</td>\n",
       "      <td>mind's got the ingredients thank you oh nothin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      username                   user_id       vid_id  \\\n",
       "4             The Lawless Tide  UCqD-eS-qRKsGi9LfT-4jiJA  RpNfMFNz2VM   \n",
       "31                    Tom Epic  UC57qJQqeVCq2BUTqvpBsHXw  EGhvfudN390   \n",
       "23                Whimsy World  UCn-yQfooWz39iQQpWYVOHdA  MlQlpU3uyss   \n",
       "40               Sabang Angler  UCxBVjI9xUjgcsJ-_z2aHjgQ  8pXx4MUDXJM   \n",
       "46        Adventure Fishing UK  UC7Da9nUj8TXcKwQlULbcpBQ  QQ7CU-CLkz0   \n",
       "38  Kapuso mo, Jessica Stories  UC_ktPLZUDrSXNOyFzhQbMpA  iXJqAxXqKS8   \n",
       "8             Final Affliction  UCcOCstS20fFk383lSHo7ifw  KvB73Ziaa70   \n",
       "33           Dung Girl Fishing  UCytnlBRb1zB8QUAZDvJr6lw  Z8PaNFb8Is8   \n",
       "7           village food taste  UCaCUtSfruaAfE3gqeT5ZHVg  6_fesOKe7NY   \n",
       "5                 Wild Fighter  UCc_lepicYywQXEvyeJcz1TA  dMZTwIDN5Bk   \n",
       "\n",
       "                    date                                              title  \\\n",
       "4   2023-10-18T20:55:00Z  Someone Called the GAME WARDEN Because I Was C...   \n",
       "31  2023-08-31T21:06:11Z  DIY Saltwater  Fish Pond  At The Beach  With A...   \n",
       "23  2023-10-16T11:42:13Z  Amazing! Attractive Best Best Big Fish Market ...   \n",
       "40  2023-09-05T11:05:21Z               Galit na Galit mga isda sa Pain ko !   \n",
       "46  2023-09-10T13:30:12Z  I Hiked HOURS to Fish this TINY Mountain Pond....   \n",
       "38  2023-10-15T11:00:29Z  Kapuso mo, Jessica soho: DAMBUHALANG COBRA, SI...   \n",
       "8   2023-09-08T07:11:38Z  The HORRIFYING Last Minutes of Gloria Serge EA...   \n",
       "33  2023-08-27T12:44:44Z  Amazing Fishing | Beautiful Girl Fishing Big a...   \n",
       "7   2023-09-30T09:33:38Z  Pond Water Fish Catching and Cooking Fish Grav...   \n",
       "5   2023-08-14T12:26:05Z  Shark Attack Man In Sea Fishing Boat | Fun Mad...   \n",
       "\n",
       "    subscribers    views  viewsToSubs  \\\n",
       "4         32600  4437572   136.121840   \n",
       "31        18500   851710    46.038378   \n",
       "23        28300  1185058    41.874841   \n",
       "40        20100   647668    32.222289   \n",
       "46        25700   573893    22.330467   \n",
       "38        69300   684191     9.872886   \n",
       "8        371000  3258808     8.783849   \n",
       "33        88600   742422     8.379481   \n",
       "7        416000  3387712     8.143538   \n",
       "5        572000  4159510     7.271871   \n",
       "\n",
       "                                     audio_transcript  \n",
       "4   oh God this is a beast definitely biggest I've...  \n",
       "31  thank you thank you foreign thank you foreign ...  \n",
       "23                                                     \n",
       "40                                                     \n",
       "46  fish on Fish on fish on yeah yes come on I thi...  \n",
       "38                                                     \n",
       "8   in today's episode an elderly woman's dog is a...  \n",
       "33                                                     \n",
       "7   foreign all right thank you thank you thank yo...  \n",
       "5   mind's got the ingredients thank you oh nothin...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These videos found a way to become discoverable by new audiences\n",
    "df.sort_values(by='viewsToSubs', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Transcript Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(vid_id):\n",
    "    try:\n",
    "        srt = YouTubeTranscriptApi.get_transcript(vid_id)\n",
    "        audio_transcription = \"\"\n",
    "        for vals in srt:\n",
    "            if vals['text'][0] == '[':\n",
    "                audio_transcription += \"\"\n",
    "            else:\n",
    "                audio_transcription += vals['text'] + \" \"\n",
    "        return audio_transcription\n",
    "    except Exception:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['audio_transcript'] = df['vid_id'].apply(get_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with LDA (Latent Dirichlet Allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kyrie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "custom_stop_words = [\n",
    "    \"fishing\", \"fish\", \"angler\", \"catch\", \"angling\", \"bait\", \"lure\", \"hook\", \n",
    "    \"reel\", \"rod\", \"line\", \"boat\", \"water\", \"lake\", \"river\", \"ocean\", \n",
    "    \"pond\", \"species\", \"tackle\", \"equipment\", \"angling\", \"angling\", \n",
    "    \"video\", \"watch\", \"subscribe\", \"channel\", \"comment\", \"like\", \"share\",\n",
    "    \"tip\", \"trick\", \"tutorial\", \"how-to\", \"guide\", \"advice\", \"vlog\", \n",
    "    \"subscribe\", \"click\", \"notification\", \"bell\", \"new\", \"latest\", \"today\",\n",
    "    \"recent\", \"upload\", \"post\", \"episode\", \"season\", \"series\", \"show\",\n",
    "    \"check\", \"visit\", \"website\", \"shop\", \"store\", \"purchase\", \"buy\", \"sale\",\n",
    "    \"discount\", \"offer\", \"promo\", \"code\", \"link\", \"description\", \"comment\",\n",
    "    \"follow\", \"social\", \"media\", \"twitter\", \"facebook\", \"instagram\",\n",
    "    \"subscribe\", \"subscribers\", \"viewer\", \"viewers\", \"audience\", \"fan\", \n",
    "    \"fans\", \"follower\", \"followers\", \"click\", \"clicks\", \"watch\", \"watches\",\n",
    "    \"watching\", \"view\", \"views\", \"watcher\", \"watchers\", \"video\", \"videos\",\n",
    "    \"clip\", \"clips\", \"episode\", \"episodes\", \"content\", \"channel\", \"channels\",\n",
    "    \"show\", \"shows\", \"season\", \"seasons\", \"series\", \"playlist\", \"playlists\",\n",
    "    \"channel\", \"channels\", \"video\", \"videos\", \"upload\", \"uploads\", \"watch\",\n",
    "    \"watching\", \"watchers\", \"viewer\", \"viewers\", \"subscribe\", \"subscribers\",\n",
    "    \"like\", \"likes\", \"dislike\", \"dislikes\", \"comment\", \"comments\", \"share\",\n",
    "    \"shares\", \"click\", \"clicks\", \"channel\", \"channels\", \"video\", \"videos\",\n",
    "    \"watch\", \"watching\", \"view\", \"views\", \"viewer\", \"viewers\", \"subscribe\",\n",
    "    \"subscribers\", \"like\", \"likes\", \"comment\", \"comments\", \"share\", \"shares\",\n",
    "    \"click\", \"clicks\", \"watch\", \"watching\", \"view\", \"views\", \"subscriber\",\n",
    "    \"subscribers\", \"like\", \"likes\", \"comment\", \"comments\", \"share\", \"shares\",\n",
    "    \"video\", \"videos\", \"channel\", \"channels\", \"watch\", \"watching\", \"view\",\n",
    "    \"views\", \"subscribe\", \"subscribers\", \"like\", \"likes\", \"comment\", \"comments\",\n",
    "    \"share\", \"shares\", \"click\", \"clicks\", \"video\", \"videos\", \"channel\", \"channels\",\n",
    "    \"watch\", \"watching\", \"view\", \"views\", \"subscribe\", \"subscribers\", \"like\",\n",
    "    \"likes\", \"comment\", \"comments\", \"share\", \"shares\", \"click\", \"clicks\",\n",
    "    \"watch\", \"watching\", \"view\", \"views\", \"subscriber\", \"subscribers\", \"like\",\n",
    "    \"likes\", \"comment\", \"comments\", \"share\", \"shares\", \"fishermen\", \"caught\",\n",
    "    \"huge\", \"one\", \"found\",\"back\",\"ever\",\"right\",\"going\",\"oh\",\"got\",\"go\",\"get\",\n",
    "    \"gonna\",\"yeah\",\"good\"\n",
    "]\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(custom_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.001*\"tide\" + 0.001*\"sergeant\" + 0.001*\"bro\" + 0.001*\"puffer\" + 0.001*\"pool\" + 0.001*\"majors\" + 0.001*\"waves\" + 0.001*\"know\" + 0.001*\"guys\" + 0.001*\"little\"')\n",
      "(1, '0.008*\"treasure\" + 0.006*\"trash\" + 0.005*\"squid\" + 0.005*\"joe\" + 0.005*\"grill\" + 0.004*\"lobster\" + 0.004*\"money\" + 0.004*\"giant\" + 0.003*\"woo\" + 0.003*\"island\"')\n",
      "(2, '0.008*\"tank\" + 0.004*\"house\" + 0.004*\"ben\" + 0.003*\"stop\" + 0.003*\"le\" + 0.003*\"hannah\" + 0.003*\"flooded\" + 0.003*\"derek\" + 0.003*\"yo\" + 0.003*\"leak\"')\n",
      "(3, '0.009*\"mac\" + 0.009*\"shark\" + 0.005*\"dogghouse\" + 0.005*\"bull\" + 0.004*\"tunnel\" + 0.004*\"bye\" + 0.004*\"tank\" + 0.004*\"beach\" + 0.004*\"dog\" + 0.004*\"fisherman\"')\n",
      "(4, '0.001*\"plush\" + 0.001*\"please\" + 0.001*\"pop\" + 0.001*\"pool\" + 0.001*\"pole\" + 0.001*\"point\" + 0.001*\"possible\" + 0.001*\"plenty\" + 0.001*\"plants\" + 0.001*\"plate\"')\n",
      "(5, '0.011*\"kitty\" + 0.006*\"creek\" + 0.006*\"catfish\" + 0.006*\"crappie\" + 0.006*\"sarang\" + 0.005*\"thailand\" + 0.004*\"bass\" + 0.004*\"tail\" + 0.004*\"india\" + 0.004*\"rat\"')\n",
      "(6, '0.008*\"knees\" + 0.007*\"toes\" + 0.006*\"sharks\" + 0.006*\"chicken\" + 0.005*\"twinkle\" + 0.005*\"fall\" + 0.004*\"corals\" + 0.004*\"row\" + 0.004*\"shoulders\" + 0.004*\"muffin\"')\n",
      "(7, '0.006*\"frog\" + 0.006*\"turtle\" + 0.005*\"sergeant\" + 0.005*\"puffer\" + 0.005*\"tide\" + 0.005*\"ratchet\" + 0.004*\"remora\" + 0.004*\"jerry\" + 0.004*\"pool\" + 0.004*\"suction\"')\n",
      "(8, '0.008*\"gloria\" + 0.007*\"alligator\" + 0.004*\"living\" + 0.004*\"trooper\" + 0.003*\"dog\" + 0.003*\"complex\" + 0.003*\"woman\" + 0.003*\"humans\" + 0.003*\"carol\" + 0.003*\"lakes\"')\n",
      "(9, '0.001*\"plush\" + 0.001*\"please\" + 0.001*\"pop\" + 0.001*\"pool\" + 0.001*\"pole\" + 0.001*\"point\" + 0.001*\"possible\" + 0.001*\"plenty\" + 0.001*\"plants\" + 0.001*\"plate\"')\n",
      "(10, '0.005*\"drum\" + 0.005*\"crabs\" + 0.004*\"bridge\" + 0.004*\"uh\" + 0.004*\"picked\" + 0.004*\"boy\" + 0.003*\"sight\" + 0.003*\"lb\" + 0.003*\"beast\" + 0.003*\"chance\"')\n",
      "(11, '0.008*\"little\" + 0.007*\"know\" + 0.006*\"really\" + 0.006*\"think\" + 0.006*\"guys\" + 0.005*\"actually\" + 0.005*\"put\" + 0.005*\"bit\" + 0.005*\"god\" + 0.005*\"come\"')\n",
      "(12, '0.007*\"tank\" + 0.006*\"landlord\" + 0.004*\"aquarium\" + 0.003*\"health\" + 0.003*\"house\" + 0.003*\"entire\" + 0.003*\"mental\" + 0.003*\"bikini\" + 0.003*\"valve\" + 0.003*\"needed\"')\n",
      "(13, '0.008*\"coconut\" + 0.005*\"yep\" + 0.003*\"macky\" + 0.003*\"cocoa\" + 0.003*\"process\" + 0.002*\"flour\" + 0.002*\"careful\" + 0.002*\"everywhere\" + 0.002*\"sharks\" + 0.001*\"finally\"')\n",
      "(14, '0.013*\"piano\" + 0.005*\"island\" + 0.004*\"sleeping\" + 0.004*\"kiro\" + 0.004*\"paddle\" + 0.004*\"board\" + 0.004*\"waterproof\" + 0.003*\"grandma\" + 0.003*\"play\" + 0.003*\"pack\"')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import LdaModel\n",
    "from gensim import matutils\n",
    "\n",
    "\n",
    "# Extract the 'text' column as a list of strings\n",
    "documents = df['audio_transcript'].tolist()\n",
    "documents_cleaned = []\n",
    "for transcripts in documents:\n",
    "    if len(transcripts) > 1000:\n",
    "        documents_cleaned.append(transcripts)\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.85, max_features=1000, stop_words=list(stop_words))\n",
    "\n",
    "# Fit and transform the documents into a TF-IDF matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents_cleaned)\n",
    "\n",
    "# Convert the TF-IDF matrix into a Gensim corpus directly\n",
    "corpus = matutils.Sparse2Corpus(tfidf_matrix, documents_columns=False)\n",
    "\n",
    "# Create a dictionary from the TF-IDF vectorizer vocabulary\n",
    "id2word = {idx: word for idx, word in enumerate(tfidf_vectorizer.get_feature_names_out())}\n",
    "\n",
    "# Train LDA model using the TF-IDF corpus\n",
    "num_topics = 15  # Choose the number of topics\n",
    "lda_model = LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics, passes=20, random_state=42)\n",
    "\n",
    "# Print topics\n",
    "topics = lda_model.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt ChatGPT for analysis of results:\n",
    "\n",
    "\"Here is a LDA output for topic frequency from popular youtube videos involving the search query \"fishing\":\n",
    "\n",
    "{insert topic output}\n",
    "\n",
    "With this information, suggest 10 topics for videos I should make as a fishing youtuber based on this data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGPT's Response\n",
    "\"\n",
    "Based on the topics extracted from popular fishing YouTube videos, here are 10 potential video topics for you as a fishing YouTuber:\n",
    "\n",
    "1. Exploring Tide Patterns: Create videos exploring different tide patterns and their impact on fishing success.\n",
    "2. Treasure and Trash Diving: Dive into underwater treasure and trash hunting, showcasing your findings.\n",
    "3. Aquarium Tank Setup: Share tips on setting up and maintaining aquarium tanks, especially focusing on fish suitable for beginners.\n",
    "4. Shark Fishing Techniques: Teach viewers various techniques for shark fishing, including bait selection and safe catch-and-release practices.\n",
    "5. Night Fishing Adventure: Capture the excitement of night fishing, discussing best practices and unique challenges faced during nighttime angling.\n",
    "6. Creative Cooking with Seafood: Showcase creative seafood recipes, demonstrating unique and delicious ways to cook fish and seafood.\n",
    "7. Exotic Fish Species: Explore exotic fish species found in different parts of the world, providing insights into their habitat and behavior.\n",
    "8. DIY Fishing Gear: Share DIY projects related to fishing gear, such as making your own lures, rods, or tackle boxes.\n",
    "9. Fishing in Unusual Locations: Take your audience to unconventional fishing spots, like bridges, piers, or even urban areas, and demonstrate successful fishing techniques there.\n",
    "10. Piano Music and Fishing: Combine your passion for fishing with music by creating relaxing piano compositions inspired by fishing experiences. Share these compositions with your viewers, creating a unique ambiance for your channel.\n",
    "\n",
    "\n",
    "Remember to tailor these ideas to your unique style and preferences, ensuring they align with your audience's interests and expectations. Good luck with your fishing YouTube channel!\n",
    "\n",
    "\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
